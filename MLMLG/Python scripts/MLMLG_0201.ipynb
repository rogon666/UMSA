{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac6091e-22a1-4f5e-ab85-32cc47efc7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Maestría en Ciencia y Análisis de Datos\n",
    "# Universidad Mayor de San Andrés\n",
    "# ----------------------------------------------------------\n",
    "#   Modelos lineales y modelos lineales generalizados\n",
    "# ----------------------------------------------------------\n",
    "#        Rolando Gonzales Martinez, Julio 2024\n",
    "# ==========================================================\n",
    "# Modelo lineal multivariante: evaluacion de modelos \n",
    "# Linealidad, normalidad, homocedasticidad y correlacion de los errores \n",
    "\n",
    "# Importando librerias:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats.api as sms\n",
    "\n",
    "\n",
    "# Cargar el conjunto de datos:\n",
    "url = 'https://raw.githubusercontent.com/rogon666/UMSA/main/MLMLG/datos/salarios.csv'\n",
    "\n",
    "# Cargar los datos en un DataFrame\n",
    "datos = pd.read_csv(url)\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame\n",
    "print(datos.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a47893-fca5-4583-bcba-f76908a3cd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las variables independientes y dependientes\n",
    "X = datos[['educacion', 'edad', 'educacion_posgrado']]\n",
    "y = datos['salario']\n",
    "\n",
    "# Añadir una constante a las variables independientes\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Ajustar el modelo de regresión lineal\n",
    "modelo_OLS = sm.OLS(y, X).fit()\n",
    "\n",
    "# Resumen del modelo\n",
    "print(modelo_OLS.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0e406f-09c5-4924-a280-31b08c835787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustando el modelo de regresion utilizando una formula:\n",
    "resultados = smf.ols(\"salario ~ educacion + edad + educacion_posgrado\", data=datos).fit()\n",
    "\n",
    "# Resultados\n",
    "print(resultados.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a1a02a-d724-4238-9387-fa7c16872854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de linealidad: Harvey-Collier\n",
    "test = sms.linear_harvey_collier(resultados)\n",
    "print(f'Estadígrafo HC: {test[0]}')\n",
    "print(f'p-value HC ~ t(n-k-1): {test[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825e8179-2f14-4cab-b021-e368afbcb070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de normalidad de residuos: Jarque-Bera\n",
    "test = sms.jarque_bera(resultados.resid)\n",
    "print(f'Estadígrafo Jarque-Bera (JB): {test[0]}')\n",
    "print(f'p-value JB ~ chi^2(2): {test[1]}')\n",
    "print(f'Sesgo: {test[2]}')\n",
    "print(f'Curtosis: {test[3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b042784-635f-406c-bdea-751479eed92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de normalidad de residuos: Omnibus de D’Agostino and Pearson\n",
    "test = sms.omni_normtest(resultados.resid)\n",
    "print(f'Estadígrafo Omni: {test[0]}')\n",
    "print(f'p-value omni ~ chi^2(2): {test[1]}')\n",
    "# D’Agostino, R. B. (1971), “An omnibus test of normality for moderate and large sample size”, Biometrika, 58, 341-348\n",
    "# D’Agostino, R. and Pearson, E. S. (1973), “Tests for departure from normality”, Biometrika, 60, 613-622"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db71953-ba9c-43e7-a838-a9ede8e1e3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Homocedasticidad: Breusch–Pagan\n",
    "test = sms.het_breuschpagan(resultados.resid, resultados.model.exog)\n",
    "print(f'Estadígrafo LMBP: {test[0]}')\n",
    "print(f'p-value LMBP ~ chi^2(k-1): {test[1]}')\n",
    "print(f'Estadígrafo FBP: {test[2]}')\n",
    "print(f'p-value FBP ~ F(k,n-k-1): {test[3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994c77fd-4497-411a-85b0-a9f37f65171b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Homocedasticidad: Goldfeld-Quandt\n",
    "test = sms.het_goldfeldquandt(resultados.resid, resultados.model.exog)\n",
    "print(f'Estadígrafo FGQ: {test[0]}')\n",
    "print(f'p-value FGQ ~ F(n1-k,n2-k): {test[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ceb0b2-0120-426f-a29b-dad9d2c7acbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Homocedasticidad: White\n",
    "from statsmodels.stats.diagnostic import het_white\n",
    "white_test = het_white(resultados.resid, resultados.model.exog)\n",
    "print(f'Estadístico LMW: {white_test[0]}')\n",
    "print(f'p-value LMW ~ chi^2(k-1): {white_test[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e972701-e674-451e-8aa9-7ae77508d06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformaciones de variables\n",
    "resultados_logsal = smf.ols(\"np.log(salario) ~ educacion + edad + educacion_posgrado\", data=datos).fit()\n",
    "\n",
    "# Resultados\n",
    "print(resultados_logsal.summary())\n",
    "\n",
    "# Test Homocedasticidad: White\n",
    "from statsmodels.stats.diagnostic import het_white\n",
    "white_test = het_white(resultados_logsal.resid, resultados_logsal.model.exog)\n",
    "print(f'Estadístico LMW: {white_test[0]}')\n",
    "print(f'p-value LMW ~ chi^2(k-1): {white_test[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7d46b4-e6d7-4ea4-8f2b-8f624adcc29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimacion con minimos cuadrados ponderados (WLS):\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calcular los residuos del modelo OLS\n",
    "residuos = modelo_OLS.resid\n",
    "\n",
    "# Calcular los pesos inversamente proporcionales a los residuos al cuadrado (o a otra medida de varianza)\n",
    "pesos = 1 / (residuos**2)\n",
    "\n",
    "# Ajustar el modelo de regresión ponderada usando WLS\n",
    "wls_model = sm.WLS(y, X, weights=pesos).fit()\n",
    "\n",
    "# Mostrar el resumen del modelo OLS\n",
    "print(\"Resumen del modelo OLS:\")\n",
    "print(modelo_OLS.summary())\n",
    "\n",
    "# Mostrar el resumen del modelo WLS\n",
    "print(\"\\nResumen del modelo WLS:\")\n",
    "print(wls_model.summary())\n",
    "\n",
    "# Graficar los residuos para observar la heterocedasticidad\n",
    "plt.scatter(modelo_OLS.fittedvalues, residuos)\n",
    "plt.xlabel('Valores Ajustados')\n",
    "plt.ylabel('Residuos')\n",
    "plt.title('Gráfico de Residuos (OLS)')\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.show()\n",
    "\n",
    "# Graficar los residuos ponderados para observar la heterocedasticidad corregida\n",
    "plt.scatter(wls_model.fittedvalues, wls_model.resid)\n",
    "plt.xlabel('Valores Ajustados')\n",
    "plt.ylabel('Residuos Ponderados')\n",
    "plt.title('Gráfico de Residuos Ponderados (WLS)')\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54ccbd1-36d3-4b02-8577-be7fc6d97184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular errores estándar robustos usando la matriz de covarianza de tipo HC3\n",
    "robust_cov = modelo_OLS.get_robustcov_results(cov_type='HC0')\n",
    "\n",
    "# Mostrar los resultados con errores estándar robustos\n",
    "print(robust_cov.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b549d559-d2f5-4aa3-ac7d-97fe08091c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlacion de los errores: Test de Durbin-Watson\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "from scipy.stats import norm\n",
    "dw_stat = durbin_watson(modelo_OLS.resid)\n",
    "print(f'Estadística de Durbin-Watson: {dw_stat}')\n",
    "# Interpretación basada en valores críticos (asumiendo un nivel de significancia de 0.05)\n",
    "# Nota: Los valores críticos dL y dU dependen de n y k\n",
    "dL = 1.738 # Valor crítico inferior para n = 177 y k = 3 (excluyendo la constante)\n",
    "dU = 1.799  # Valor crítico superior para n = 177 y k = 3 (excluyendo la constante)\n",
    "if dw_stat < dL:\n",
    "    print(\"Evidencia de autocorrelación positiva de primer orden\")\n",
    "elif dL <= dw_stat <= dU:\n",
    "    print(\"Prueba inconclusa.\")\n",
    "else:\n",
    "    print(\"No hay evidencia de autocorrelación positiva.\")\n",
    "# Nota: el estadigrafo DW es sesgado (subestima autocorrelacion) en el contexto de AR(I)MA\n",
    "# Calcular la estadística H de Durbin-Watson\n",
    "residuos = modelo_OLS.resid\n",
    "rho_hat = np.corrcoef(residuos[:-1], residuos[1:])[0, 1]\n",
    "n = len(modelo_OLS.resid)\n",
    "k = 5  # Número de variables explicativas excluyendo la constante\n",
    "h_stat = (1 - dw_stat / 2) * np.sqrt(n / (1 - n * (rho_hat**2)))\n",
    "print(f'Estadígrafo H de Durbin-Watson: {h_stat}')\n",
    "# Evaluar la estadística H usando la distribución normal estándar\n",
    "alpha = 0.05 # significancia de 5%\n",
    "z_critical = norm.ppf(1 - alpha / 2)  # Valor crítico para un nivel de significancia de 5%\n",
    "print(f'Valor crítico z para H: {z_critical}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40f0ab8-3f22-4fad-8a03-8e64bc880a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlacion de los errores: Test Breusch-Godfrey\n",
    "from statsmodels.stats.diagnostic import acorr_breusch_godfrey\n",
    "bg_test = acorr_breusch_godfrey(modelo_OLS, nlags=5)\n",
    "# Resultados del test de Breusch-Godfrey\n",
    "print(f'Estadístico LM: {bg_test[0]}')\n",
    "print(f'Valor p (LM): {bg_test[1]}')\n",
    "print(f'Estadístico F: {bg_test[2]}')\n",
    "print(f'Valor p (F): {bg_test[3]}')\n",
    "# Interpretación de los resultados\n",
    "alpha = 0.05\n",
    "if bg_test[1] < alpha:\n",
    "    print(\"Se rechaza la hipótesis nula de no correlación de los errores. \\nExiste evidencia de correlación de los errores.\")\n",
    "else:\n",
    "    print(\"No se rechaza la hipótesis nula de no correlación de los errores. \\nNo hay evidencia de correlación de los errores.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229f1275-d9d6-4560-8548-5ad752cfd31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar la función de autocorrelación de los residuos\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "plot_acf(modelo_OLS.resid)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b3258a-7c4c-4eb2-a20d-0d5e7962720e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el número de rezagos usando la regla de Parzen\n",
    "n = len(y)\n",
    "rezagos_parzen = int(0.75 * n**(1/3))\n",
    "print(f\"Número de rezagos según la regla de Parzen: {rezagos_parzen}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa067037-d847-4e53-a2cd-b472982ffb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados con la matriz varianza-covarianza Newey-West:\n",
    "neweywest_cov = modelo_OLS.get_robustcov_results(cov_type='HAC', \n",
    "                                                 maxlags=4, \n",
    "                                                 use_correction=True)\n",
    "print(neweywest_cov.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd6546a-4601-4332-a052-f3f692e913eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisis de observaciones influyentes:\n",
    "influencia = modelo_OLS.get_influence()\n",
    "# Obtener los valores de leverage\n",
    "apanlacamiento = influencia.hat_matrix_diag\n",
    "# Graficar los valores de apanlacamiento (leverage)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.stem(apanlacamiento)\n",
    "plt.xlabel('Índice de la observación')\n",
    "plt.ylabel('Leverage')\n",
    "plt.title('Valores de apanlacamiento (leverage) para cada observación')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c4262b-7f10-4d1e-8f35-4d344096e823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distancia de Cook\n",
    "d_cook = influencia.cooks_distance[0]\n",
    "# Valores mayores a 1 sugieren observaciones influyentes.\n",
    "# Generar el gráfico de Distancia de Cook\n",
    "umbral = 1 \n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.stem(d_cook)\n",
    "plt.axhline(y=umbral, color='r', linestyle='--', label=f'Umbral = {umbral:.2f}')\n",
    "plt.xlabel('Índice de la observación')\n",
    "plt.ylabel('Distancia de Cook')\n",
    "plt.title('Distancia de Cook para cada observación')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa96adba-c6a3-4cad-af4a-42bc16d63a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafico de influencia:\n",
    "from statsmodels.graphics.regressionplots import influence_plot\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "influence_plot(modelo_OLS, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4b2de5-2ba5-4b46-9e0f-38fc209dba83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar el nuevo modelo sin observaciones influyentes\n",
    "obs_a_remover = 102\n",
    "# Eliminar la fila especificada\n",
    "# Definir las variables independientes y dependientes\n",
    "X = datos[['educacion', 'edad', 'educacion_posgrado','antiguedad_ejecutivo']]\n",
    "y = datos['salario']\n",
    "X_ni = np.delete(X, obs_a_remover, axis=0)\n",
    "y_ni = np.delete(y, obs_a_remover, axis=0)\n",
    "X_ni = sm.add_constant(X_ni)\n",
    "#X_ni.columns = ['constante', 'educacion', 'edad','educacion_posgrado','antiguedad_ejecutivo'] \n",
    "X_ni = pd.DataFrame(X_ni, columns=['constante','educacion', 'edad', 'educacion_posgrado', 'antiguedad_ejecutivo'])\n",
    "# Resumen del nuevo modelo ajustado\n",
    "modelo_ni = sm.OLS(y_ni, X_ni).fit()\n",
    "print(modelo_ni.summary())\n",
    "robust_cov_ni = modelo_ni.get_robustcov_results(cov_type='HC0')\n",
    "neweywest_cov = modelo_ni.get_robustcov_results(cov_type='HAC', maxlags=4, use_correction=True)\n",
    "print(robust_cov_ni.summary())\n",
    "print(neweywest_cov.summary())\n",
    "print('--------------- Correlación en los residuos -----------------------')\n",
    "bg_test = acorr_breusch_godfrey(modelo_OLS, nlags=5)\n",
    "print(f'Estadístico LM: {bg_test[0]}')\n",
    "print(f'Valor p (LM): {bg_test[1]}')\n",
    "print(f'Estadístico F: {bg_test[2]}')\n",
    "print(f'Valor p (F): {bg_test[3]}')\n",
    "alpha = 0.05\n",
    "if bg_test[1] < alpha:\n",
    "    print(\"Se rechaza la hipótesis nula de no correlación de los errores. \\nExiste evidencia de correlación de los errores.\")\n",
    "else:\n",
    "    print(\"No se rechaza la hipótesis nula de no correlación de los errores. \\nNo hay evidencia de correlación de los errores.\")\n",
    "white_test = het_white(resultados_logsal.resid, resultados_logsal.model.exog)\n",
    "print('--------------- Heterocedasticidad en los residuos -----------------------')\n",
    "print(f'Estadístico LMW: {white_test[0]}')\n",
    "print(f'p-value LMW ~ chi^2(k-1): {white_test[1]}')\n",
    "if white_test[1] < alpha:\n",
    "    print(\"Se rechaza la hipótesis nula de homocedasticidad. \\nExiste evidencia de heterocedasticidad de los errores.\")\n",
    "else:\n",
    "    print(\"No se rechaza la hipótesis nula de homocedasticidad. \\nNo hay evidencia de heterocedasticidad de los errores.\")\n",
    "print('============================================================================')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2024.02-py310",
   "language": "python",
   "name": "conda-env-anaconda-2024.02-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
