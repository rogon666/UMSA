{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d94fadd-af31-4caf-a8b4-be8a9fa4279a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Maestr칤a en Ciencia y An치lisis de Datos\n",
    "# Universidad Mayor de San Andr칠s\n",
    "# ----------------------------------------------------------\n",
    "#           Machine Learning y Deep Learning\n",
    "# ----------------------------------------------------------\n",
    "#        Rolando Gonzales Martinez, Agosto 2024\n",
    "# ==========================================================\n",
    "#            Maquinas de soporte vectorial\n",
    "# ==========================================================\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Crear un dataset simple para clasificaci칩n binaria\n",
    "X, y = datasets.make_blobs(n_samples=100, centers=2, random_state=6)\n",
    "\n",
    "# Crear el modelo de SVM lineal\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Obtener el vector de pesos (coeficientes) y el intercepto\n",
    "w = clf.coef_[0]\n",
    "b = clf.intercept_[0]\n",
    "\n",
    "# Crear el hiperplano\n",
    "x_plot = np.linspace(min(X[:, 0]), max(X[:, 0]), 100)\n",
    "y_plot = -(w[0] * x_plot + b) / w[1]\n",
    "\n",
    "# Obtener los vectores de soporte\n",
    "support_vectors = clf.support_vectors_\n",
    "\n",
    "# Margen\n",
    "margin = 1 / np.sqrt(np.sum(clf.coef_ ** 2))\n",
    "y_margin_up = y_plot + margin\n",
    "y_margin_down = y_plot - margin\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='winter', label='Puntos de datos')\n",
    "\n",
    "# Hiperplano y m치rgenes\n",
    "plt.plot(x_plot, y_plot, 'r-', label='Hiperplano')\n",
    "plt.plot(x_plot, y_margin_up, 'g--', label='Margen superior')\n",
    "plt.plot(x_plot, y_margin_down, 'g--', label='Margen inferior')\n",
    "\n",
    "plt.scatter(support_vectors[:, 0], support_vectors[:, 1], s=200, facecolors='yellow', edgecolors='black', label='Vectores de soporte')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.title('Vectores de Soporte y plano de una SVM')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b08edc2-bdda-4d7e-b35b-95f1fc3c772e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Crear un conjunto de datos no linealmente separable\n",
    "X, y = make_circles(n_samples=100, factor=0.3, noise=0.1)\n",
    "\n",
    "# Crear un modelo SVM con kernel lineal\n",
    "svm_linear = SVC(kernel='linear')\n",
    "svm_linear.fit(X, y)\n",
    "\n",
    "# Crear un modelo SVM con kernel RBF (trick del kernel)\n",
    "svm_rbf = SVC(kernel='rbf', gamma=1)\n",
    "svm_rbf.fit(X, y)\n",
    "\n",
    "# Crear una malla para graficar las fronteras de decisi칩n\n",
    "xx, yy = np.meshgrid(np.linspace(-1.5, 1.5, 500), np.linspace(-1.5, 1.5, 500))\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "# Predicciones\n",
    "Z_linear = svm_linear.decision_function(grid).reshape(xx.shape)\n",
    "Z_rbf = svm_rbf.decision_function(grid).reshape(xx.shape)\n",
    "\n",
    "# Graficar los resultados\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Subplot para SVM con kernel lineal\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.contourf(xx, yy, Z_linear, levels=np.linspace(Z_linear.min(), 0, 7), cmap=plt.cm.viridis)\n",
    "plt.contour(xx, yy, Z_linear, levels=[0], linewidths=2, colors='red')\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.plasma, s=50, edgecolors='black')\n",
    "plt.title(\"SVM con Kernel Lineal\")\n",
    "plt.xlabel(\"X1\")\n",
    "plt.ylabel(\"X2\")\n",
    "\n",
    "# Subplot para SVM con kernel RBF\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.contourf(xx, yy, Z_rbf, levels=np.linspace(Z_rbf.min(), 0, 7), cmap=plt.cm.viridis)\n",
    "plt.contour(xx, yy, Z_rbf, levels=[0], linewidths=2, colors='red')\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.plasma, s=50, edgecolors='black')\n",
    "plt.title(\"SVM con Kernel RBF\")\n",
    "plt.xlabel(\"X1\")\n",
    "plt.ylabel(\"X2\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f292d71-6c92-42bf-8ca8-9cb3215e3c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Crear un conjunto de datos con un poco de superposici칩n entre clases\n",
    "X, y = make_blobs(n_samples=100, centers=2, random_state=6, cluster_std=1.5)\n",
    "\n",
    "# Crear un modelo SVM con margen suave (Soft SVM)\n",
    "C_value = 0.1\n",
    "soft_svm = SVC(kernel='linear', C=C_value)\n",
    "soft_svm.fit(X, y)\n",
    "# El par치metro 洧냤 controla el trade-off entre maximizar el margen y minimizar \n",
    "# los errores de clasificaci칩n en el conjunto de entrenamiento\n",
    "\n",
    "# Extraer los vectores de soporte y el hiperplano\n",
    "support_vectors = soft_svm.support_vectors_\n",
    "w = soft_svm.coef_[0]\n",
    "b = soft_svm.intercept_[0]\n",
    "\n",
    "# Crear el hiperplano\n",
    "x_plot = np.linspace(min(X[:, 0]), max(X[:, 0]), 100)\n",
    "y_plot = -(w[0] * x_plot + b) / w[1]\n",
    "\n",
    "# Crear los m치rgenes\n",
    "margin = 1 / np.sqrt(np.sum(w**2))\n",
    "y_margin_up = y_plot + margin\n",
    "y_margin_down = y_plot - margin\n",
    "\n",
    "# Cambiar colores del gr치fico para mayor contraste y claridad\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Colores personalizados para las dos clases\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='winter', label='Puntos de datos')\n",
    "\n",
    "# Hiperplano y m치rgenes\n",
    "plt.plot(x_plot, y_plot, 'r-', label='Hiperplano')\n",
    "plt.plot(x_plot, y_margin_up, 'g--', label='Margen superior')\n",
    "plt.plot(x_plot, y_margin_down, 'g--', label='Margen inferior')\n",
    "\n",
    "# Resaltar los vectores de soporte con otro color\n",
    "plt.scatter(support_vectors[:, 0], support_vectors[:, 1], s=200, facecolors='none', edgecolors='black', label='Vectores de soporte')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.title(f'Soft SVM: Vectores de Soporte e Hiperplano (C = {C_value})')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4323fe7-5ffb-4ebc-9322-36da0276c3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Crear un conjunto de datos con un poco de superposici칩n entre clases\n",
    "X, y = make_blobs(n_samples=100, centers=2, random_state=6, cluster_std=1.5)\n",
    "\n",
    "# Crear un modelo SVM con margen suave (Soft SVM)\n",
    "C_value = 0.9\n",
    "soft_svm = SVC(kernel='linear', C=C_value)\n",
    "soft_svm.fit(X, y)\n",
    "\n",
    "# Extraer los vectores de soporte y el hiperplano\n",
    "support_vectors = soft_svm.support_vectors_\n",
    "w = soft_svm.coef_[0]\n",
    "b = soft_svm.intercept_[0]\n",
    "\n",
    "# Crear el hiperplano\n",
    "x_plot = np.linspace(min(X[:, 0]), max(X[:, 0]), 100)\n",
    "y_plot = -(w[0] * x_plot + b) / w[1]\n",
    "\n",
    "# Crear los m치rgenes\n",
    "margin = 1 / np.sqrt(np.sum(w**2))\n",
    "y_margin_up = y_plot + margin\n",
    "y_margin_down = y_plot - margin\n",
    "\n",
    "# Cambiar colores del gr치fico para mayor contraste y claridad\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Colores personalizados para las dos clases\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='winter', label='Puntos de datos')\n",
    "\n",
    "# Hiperplano y m치rgenes\n",
    "plt.plot(x_plot, y_plot, 'r-', label='Hiperplano')\n",
    "plt.plot(x_plot, y_margin_up, 'g--', label='Margen superior')\n",
    "plt.plot(x_plot, y_margin_down, 'g--', label='Margen inferior')\n",
    "\n",
    "# Resaltar los vectores de soporte con otro color\n",
    "plt.scatter(support_vectors[:, 0], support_vectors[:, 1], s=200, facecolors='none', edgecolors='black', label='Vectores de soporte')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.title(f'Soft SVM: Vectores de Soporte e Hiperplano (C = {C_value})')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-ai-2024.04-py310",
   "language": "python",
   "name": "conda-env-anaconda-ai-2024.04-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
